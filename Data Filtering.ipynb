{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cleantext import clean\n",
    "from pandarallel import pandarallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import databricks.koalas as ks\n",
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_session = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"app\") \\\n",
    "    .master(\"local[50]\") \\\n",
    "    .config(\"spark.driver.memory\",\"40G\")\\\n",
    "    .getOrCreate();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_dir = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = os.path.join(filtered_dir,'BoDeGHa_data_onefile/BoDeGHa_data.csv')\n",
    "# comments = pd.read_csv(path, quotechar='\"', escapechar='\\\\')\n",
    "# # comments = comments[comments['repo_id']==str(repository)].drop(columns=['repo_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comments[comments['repo_id']==213].drop(columns=['repo_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# format text file for easier read (run this on .py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 50 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "# pandarallel.initialize(nb_workers=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# header_list = [\"pull_request_id\",\"user_id\",\"comment_id\",\"position\",\"body\",\"commit_id\",\"created_at\"]\n",
    "# pull_request_comments = pd.read_csv(os.path.join(data_path,'pull_request_comments.csv'), header=None, names=header_list, quotechar='\"', escapechar='\\\\')\n",
    "# pull_request_comments['body'] = pull_request_comments.parallel_apply(lambda row: clean(row['body'], no_line_breaks=True),axis = 1)\n",
    "# pull_request_comments['created_at'] =  pd.to_datetime(pull_request_comments['created_at'], format='%Y-%m-%d %H:%M:%S')\n",
    "# pull_request_comments.to_csv(os.path.join(filtered_dir,'easy_read/pull_request_comments2.csv'), quotechar='\"', escapechar='\\\\')\n",
    "# pull_request_comments = ks.from_pandas(pull_request_comments)\n",
    "# pull_request_comments.to_csv(os.path.join(filtered_dir,'easy_read/pull_request_comments'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# header_list = [\"id\" ,\"url\" ,\"owner_id\" ,\"name\" ,\"description\" ,\"language\" ,\"created_at\" ,\"forked_from\" ,\"deleted\" ,\"updated_at\" ,\"forked_commit_id\"]\n",
    "# projects = pd.read_csv(os.path.join(data_path,'projects.csv'), header=None, names=header_list, quotechar='\"', escapechar='\\\\')\n",
    "# projects['description'] = projects.parallel_apply(lambda row: clean(row['description'], no_line_breaks=True),axis = 1)\n",
    "# projects.to_csv(os.path.join(filtered_dir,'easy_read/projects.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunksize = 10 ** 6\n",
    "# header_list = [\"id\" ,\"url\" ,\"owner_id\" ,\"name\" ,\"description\" ,\"language\" ,\"created_at\" ,\"forked_from\" ,\"deleted\" ,\"updated_at\" ,\"forked_commit_id\"]\n",
    "\n",
    "# header = True\n",
    "# for chunk in tqdm(pd.read_csv(os.path.join(data_path,'projects.csv'), header=None, names=header_list, quotechar='\"', escapechar='\\\\', chunksize=chunksize)):\n",
    "#     chunk = chunk.drop('description', axis=1)\n",
    "#     chunk.to_csv(os.path.join(filtered_dir,'easy_read/no_descp_projects.csv'),header=header, mode='a', index=False)\n",
    "#     header = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandarallel.initialize()\n",
    "# chunksize = 10 ** 6\n",
    "# header_list = [\"pull_request_id\",\"user_id\",\"comment_id\",\"position\",\"body\",\"commit_id\",\"created_at\"]\n",
    "\n",
    "# header = True\n",
    "# for chunk in tqdm(pd.read_csv(os.path.join(data_path,'pull_request_comments.csv'), header=None, names=header_list, quotechar='\"', escapechar='\\\\', chunksize=chunksize)):\n",
    "#     chunk['body'] = chunk.parallel_apply(lambda row: clean(row['body'], no_line_breaks=True),axis = 1)\n",
    "#     chunk.to_csv(os.path.join(filtered_dir,'easy_read/pull_request_comments.csv'),header=header, mode='a', index=False)\n",
    "#     header = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# header_list = \"id int,sha string,author_id int,committer_id int,project_id int,created_at timestamp\"\n",
    "header_list = [\"id\",\"sha\",\"author_id\",\"committer_id\",\"project_id\",\"created_at\"]\n",
    "commits = ks.read_csv(os.path.join(data_path,'commits.csv'), header=None, names=header_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# header_list = \"id int,url string,owner_id int,name string,description string,language string,created_at timestamp,forked_from int,deleted int,updated_at timestamp,forked_commit_id int\"\n",
    "# header_list = [\"id\" ,\"url\" ,\"owner_id\" ,\"name\" ,\"language\" ,\"created_at\" ,\"forked_from\" ,\"deleted\" ,\"updated_at\" ,\"forked_commit_id\"]\n",
    "projects = ks.read_csv(os.path.join(filtered_dir,'easy_read/no_descp_projects.csv'))\n",
    "# projects = spark_session.read.csv(os.path.join(data_path,'projects.csv'), multiLine=True,header=False)\n",
    "# projects = ks.DataFrame(projects)\n",
    "# projects.columns=header_list\n",
    "# projects.write.csv(os.path.join(filtered_dir,'projects_easyread'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = 'select * from {projects} where id = 213'\n",
    "test = ks.sql(sql)\n",
    "test.to_pandas()['url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_list = [\"id\",\"login\",\"company\",\"created_at\",\"type\",\"fake\",\"deleted\",\"long\",\"lat\",\"country_code\",\"state\",\"city\",\"location\"]\n",
    "users = ks.read_csv(os.path.join(data_path,'users.csv'), header=None, names=header_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+-------+-------------------+----+----+-------+-----------+-----------+------------+-------------+------+---------------+\n",
      "|     id|login|company|         created_at|type|fake|deleted|       long|        lat|country_code|        state|  city|       location|\n",
      "+-------+-----+-------+-------------------+----+----+-------+-----------+-----------+------------+-------------+------+---------------+\n",
      "|1396688|bl4de|     \\N|2013-01-04 17:16:30| USR|   0|      0|-6.26749000|53.34410000|          IE|County Dublin|Dublin|Dublin, Ireland|\n",
      "+-------+-----+-------+-------------------+----+----+-------+-----------+-----------+------------+-------------+------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql = 'select * from {users} where id = 1396688'\n",
    "test = ks.sql(sql)\n",
    "test.to_spark().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # header_list =\"project_id int, language string, bytes int, created_at timestamp\"\n",
    "# header_list =[\"project_id\",\" language\",\" bytes\",\" created_at timestamp\"]\n",
    "# project_languages = ks.read_csv(os.path.join(data_path,'project_languages.csv'), header=None, names=header_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter out project in other language and deleted project and original project (not fork)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_language = ['C', 'C++', 'Java', 'JavaScript','Python', 'PHP', 'Ruby']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = 'select * from {projects} p where p.language in {selected_language} and p.deleted == 0 and forked_from==\"N\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_projects = ks.sql(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_projects.to_csv(os.path.join(filtered_dir,'projects'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_language = ['Python']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = 'select url, name from {projects} p where p.language in {selected_language} and p.deleted == 0 and forked_from==\"N\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_projects = ks.sql(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_projects.to_csv(os.path.join(filtered_dir,'python_projects_name_url'),num_files=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reload projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "projects = ks.read_csv(os.path.join(filtered_dir,'projects/*.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate number of project's commits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"select p.id as project_id, p.url, p.language, p.created_at as project_created_at , p.updated_at, c.id as commit_id, c.created_at as commit_created_at from {projects} p inner join {commits} c on c.project_id == p.id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_commits = ks.sql(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_commits.to_csv(os.path.join(filtered_dir,'project_commits'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+--------+-------------------+-------------------+---------+-------------------+\n",
      "|project_id|                 url|language| project_created_at|         updated_at|commit_id|  commit_created_at|\n",
      "+----------+--------------------+--------+-------------------+-------------------+---------+-------------------+\n",
      "|       833|https://api.githu...|    Ruby|2010-09-16 15:34:02|2020-10-11 12:43:29|    15994|2012-06-09 06:28:50|\n",
      "|       833|https://api.githu...|    Ruby|2010-09-16 15:34:02|2020-10-11 12:43:29|    15999|2012-06-09 05:12:00|\n",
      "|       833|https://api.githu...|    Ruby|2010-09-16 15:34:02|2020-10-11 12:43:29|  1399920|2012-08-02 23:50:38|\n",
      "|       833|https://api.githu...|    Ruby|2010-09-16 15:34:02|2020-10-11 12:43:29|  1400182|2012-08-02 23:51:37|\n",
      "|       833|https://api.githu...|    Ruby|2010-09-16 15:34:02|2020-10-11 12:43:29|  1400186|2012-08-02 23:51:07|\n",
      "|       833|https://api.githu...|    Ruby|2010-09-16 15:34:02|2020-10-11 12:43:29|  1400390|2012-08-02 23:51:56|\n",
      "|       833|https://api.githu...|    Ruby|2010-09-16 15:34:02|2020-10-11 12:43:29|  1400956|2012-08-02 23:53:22|\n",
      "|       833|https://api.githu...|    Ruby|2010-09-16 15:34:02|2020-10-11 12:43:29|  1401160|2012-08-02 23:54:36|\n",
      "|       833|https://api.githu...|    Ruby|2010-09-16 15:34:02|2020-10-11 12:43:29|  1553790|2012-08-03 09:49:27|\n",
      "|       833|https://api.githu...|    Ruby|2010-09-16 15:34:02|2020-10-11 12:43:29|  3654425|2012-01-30 16:33:49|\n",
      "|       833|https://api.githu...|    Ruby|2010-09-16 15:34:02|2020-10-11 12:43:29|  3654426|2012-01-30 15:52:22|\n",
      "|       833|https://api.githu...|    Ruby|2010-09-16 15:34:02|2020-10-11 12:43:29|  3862153|2012-06-19 18:50:12|\n",
      "|       833|https://api.githu...|    Ruby|2010-09-16 15:34:02|2020-10-11 12:43:29|  3984623|2012-02-19 17:23:12|\n",
      "|       833|https://api.githu...|    Ruby|2010-09-16 15:34:02|2020-10-11 12:43:29|  3984624|2012-02-19 17:19:36|\n",
      "|       833|https://api.githu...|    Ruby|2010-09-16 15:34:02|2020-10-11 12:43:29|  4359544|2012-03-16 17:16:56|\n",
      "|       833|https://api.githu...|    Ruby|2010-09-16 15:34:02|2020-10-11 12:43:29|  4359546|2012-03-16 17:05:10|\n",
      "|       833|https://api.githu...|    Ruby|2010-09-16 15:34:02|2020-10-11 12:43:29|  4877718|2012-04-11 08:05:43|\n",
      "|       833|https://api.githu...|    Ruby|2010-09-16 15:34:02|2020-10-11 12:43:29|  4877719|2012-04-11 08:05:21|\n",
      "|       833|https://api.githu...|    Ruby|2010-09-16 15:34:02|2020-10-11 12:43:29|  4877721|2012-04-10 22:22:00|\n",
      "|       833|https://api.githu...|    Ruby|2010-09-16 15:34:02|2020-10-11 12:43:29|  4909437|2012-04-12 18:34:36|\n",
      "+----------+--------------------+--------+-------------------+-------------------+---------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "project_commits.to_spark().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_commits = ks.read_csv(os.path.join(filtered_dir,'project_commits/*.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter only project that have commit more than 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"select project_id, count(commit_id) from {project_commits} pc group by project_id having count(commit_id) > 500\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_commit_project = ks.sql(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------------+\n",
      "|project_id|count(commit_id)|\n",
      "+----------+----------------+\n",
      "|       833|            1601|\n",
      "|      1088|          117966|\n",
      "|      3794|            2799|\n",
      "|      3918|            3540|\n",
      "|      4900|            1177|\n",
      "|      6620|             525|\n",
      "|      7880|             537|\n",
      "|      7982|             914|\n",
      "|      9427|           23743|\n",
      "|      9900|             934|\n",
      "|     10362|            4006|\n",
      "|     13285|             554|\n",
      "|     13289|            8307|\n",
      "|     16861|            2149|\n",
      "|     18800|            1518|\n",
      "|     18944|            3168|\n",
      "|     28577|            3060|\n",
      "|     29894|            6176|\n",
      "|     43688|            1238|\n",
      "|     48254|            2585|\n",
      "+----------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "count_commit_project.to_spark().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_project = count_commit_project['project_id'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_project = [int(i) for i in selected_project]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"select * from {project_commits} cp where cp.project_id in {selected_project}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_commits = ks.sql(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_commits.to_csv(os.path.join(filtered_dir,'project_commits_500commit'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_commits = ks.read_csv(os.path.join(filtered_dir,'project_commits_500commit/*.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# most active 2 year filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"select project_id, YEAR(commit_created_at), count(commit_id) from {project_commits} pc group by project_id, YEAR(commit_created_at) order by project_id, YEAR(commit_created_at)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_commit_project = ks.sql(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_commit_project.to_spark().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_commit_project_year_df = count_commit_project.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_proj = 3\n",
    "current_count = 0\n",
    "remove_project = []\n",
    "for i, row in tqdm(count_commit_project_year_df.iterrows(),total= count_commit_project_year_df.shape[0]):\n",
    "    if row['project_id'] != current_proj:\n",
    "        if current_count < 2:\n",
    "            remove_project.append(current_proj)\n",
    "        current_proj = row['project_id']\n",
    "        current_count = 0\n",
    "    current_count = current_count + (1 if row['count(commit_id)'] > 100 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_project = [int(i) for i in remove_project]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"select * from {project_commits} cp where cp.project_id not in {remove_project}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_commits = ks.sql(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_commits.to_csv(os.path.join(filtered_dir,'project_commits_500commit_100mostactive2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_commits = ks.read_csv(os.path.join(filtered_dir,'project_commits_500commit_100mostactive2/*.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Candidate project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"select distinct project_id from {project_commits}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_project = ks.sql(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_project = [int(i) for i in candidate_project.to_pandas()['project_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72635"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(candidate_project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(filtered_dir,\"candidate_projects\"),'wb') as outfile:\n",
    "    pickle.dump(candidate_project,outfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(filtered_dir,\"candidate_projects\"),'rb') as infile:\n",
    "    candidate_project = pickle.load(infile)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter pull_request (make file smaller only candidate project pull reqeust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_list = [\"id\",\"head_repo_id\",\"base_repo_id\",\"head_commit_id\",\"base_commit_id\",\"pullreq_id\",\"intra_branch\"]\n",
    "pull_requests = ks.read_csv(os.path.join(data_path,'pull_requests.csv'), header=None, names=header_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_list = [\"id\",\"pull_request_id\",\"created_at\",\"action\",\"actor_id\"]\n",
    "pull_request_history = ks.read_csv(os.path.join(data_path,'pull_request_history.csv'), header=None, names=header_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# header_list = [\"pull_request_id\",\"user_id\",\"comment_id\",\"position\",\"body\",\"commit_id\",\"created_at\"]\n",
    "pull_request_comments = ks.read_csv(os.path.join(filtered_dir,'easy_read/pull_request_comments.csv'))\n",
    "# pull_request_comments = spark_session.read.option(\"header\",False).option(\"multiline\",True).csv(os.path.join(data_path,'pull_request_comments.csv'))\n",
    "# pull_request_comments = ks.DataFrame(pull_request_comments)\n",
    "# pull_request_comments.columns=header_list\n",
    "# pull_request_comments.to_csv(os.path.join(filtered_dir,'pull_request_comments_easy_read/pull_request_comments.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = 'select * from {pull_requests} pr where pr.base_repo_id in {candidate_project}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pull_requests = ks.sql(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pull_requests.to_csv(os.path.join(filtered_dir,'pull_requests'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pull_requests = ks.read_csv(os.path.join(filtered_dir,'pull_requests/*.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter issue (make file smaller only candidate project issue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_list = [\"id\",\"repo_id\",\"reporter_id\",\"assignee_id\",\"pull_request\",\"pull_request_id\",\"created_at\",\"issue_id\"]\n",
    "issues = ks.read_csv(os.path.join(data_path,'issues.csv'), header=None, names=header_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = 'select * from {issues} where repo_id in {candidate_project}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "issues = ks.sql(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "issues.to_csv(os.path.join(filtered_dir,'issues'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "issues = ks.read_csv(os.path.join(filtered_dir,'issues/*.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"select language,distinct project_id project_id from {project_commits}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_language = ks.sql(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_language.to_csv(os.path.join(filtered_dir,'project_language'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>project_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JavaScript</td>\n",
       "      <td>18504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C++</td>\n",
       "      <td>9052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>8071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PHP</td>\n",
       "      <td>7008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ruby</td>\n",
       "      <td>4363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Python</td>\n",
       "      <td>14102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Java</td>\n",
       "      <td>11535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     language  project_id\n",
       "0  JavaScript       18504\n",
       "1         C++        9052\n",
       "2           C        8071\n",
       "3         PHP        7008\n",
       "4        Ruby        4363\n",
       "5      Python       14102\n",
       "6        Java       11535"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
